import pickle
import numpy
from music21 import instrument, note, stream, chord


def notes_generator(samples=16):
    import pickle
    import numpy as np
    from music21 import instrument, note, stream, chord
    #     notes = get_notes()
    import pickle
    with open('data/notes', 'rb') as filepath:
        notes = pickle.load(filepath)
    from keras import models

    batch_size = 32
    #     generator = generator_model()
    for i in range(samples):
        noise = np.random.uniform(-1, 1, size=[batch_size, 100])  # np.random.normal(0, 1, size=[batch_size, 100])
        generator = models.load_model('generator100.h5')
        #         gan1 = models.load_model('gan1.h5')
        generated_notes = generator.predict(noise)

    predictions = []

    prob = generated_notes
    y_pred = np.argmax(prob, axis=0)

    predictions.append(y_pred)

    x_int_to_note = dict((number, note_) for number, note_ in enumerate(notes))
    predicted_notes = [x_int_to_note[i] for i in y_pred]
    print("predicted_notes", predicted_notes)
    convert_to_midi(predicted_notes)


def convert_to_midi(prediction_output):
    from music21 import stream
    #     from midi2audio import FluidSynth
    offset = 0
    output_notes = []

    # create note and chord objects based on the values generated by the model
    for pattern in prediction_output:

        # pattern is a chord
        if ('.' in pattern) or pattern.isdigit():
            notes_in_chord = pattern.split('.')
            notes = []
            for current_note in notes_in_chord:
                cn = int(current_note)
                new_note = note.Note(cn)
                new_note.storedInstrument = instrument.Piano()
                notes.append(new_note)

            new_chord = chord.Chord(notes)
            new_chord.offset = offset
            output_notes.append(new_chord)

        # pattern is a note
        else:

            new_note = note.Note(pattern)
            new_note.offset = offset
            new_note.storedInstrument = instrument.Piano()  # Piano
            output_notes.append(new_note)

        # increase offset each iteration so that notes do not stack
        offset += 1
    midi_stream = stream.Stream(output_notes)
    midi_stream.write('midi', fp='music_206.mid')


from tkinter import *

from pygame import mixer


def play_file():
    root = Tk()

    mixer.init()  # initializing the mixer

    root.geometry('600x600')
    root.title("GAN generated music")
    root.iconbitmap(r'melody.ico')
    bgImage = PhotoImage(file=r"BG.png")
    Label(root, image=bgImage).place(relwidth=1, relheight=1)

    #     text = Label(root, text='Press the button below to generate music')
    #     text.pack()

    def play_music():
        mixer.music.load("music_206.mid")
        mixer.music.play()

    def stop_music():
        mixer.music.stop()

    playBtn = Button(root, text="Ready to play the music", width=40, command=notes_generator(samples=16))
    playBtn.pack()

    play_photo = PhotoImage(file='play.png')
    playBtn = Button(root, image=play_photo, command=play_music)
    playBtn.pack()

    stop_photo = PhotoImage(file='stop.png')
    stopBtn = Button(root, image=stop_photo, command=stop_music)
    stopBtn.pack()

    root.mainloop()


if __name__ == '__main__':
    play_file()