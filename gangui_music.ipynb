{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy\n",
    "from music21 import instrument, note, stream, chord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def notes_generator(samples=16):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "    from music21 import instrument, note, stream, chord\n",
    "#     notes = get_notes()\n",
    "    import pickle\n",
    "    with open('data/notes', 'rb') as filepath:\n",
    "        notes = pickle.load(filepath)\n",
    "    from keras import models\n",
    "    \n",
    "    batch_size = 32\n",
    "#     generator = generator_model()\n",
    "    for i in range(samples):\n",
    "        noise = np.random.uniform(-1, 1, size=[batch_size, 100])#np.random.normal(0, 1, size=[batch_size, 100])\n",
    "        generator = models.load_model('generator100.h5')\n",
    "#         gan1 = models.load_model('gan1.h5')\n",
    "        generated_notes = generator.predict(noise)\n",
    "        \n",
    "#         print(\"\\n Notes Generated: \", generated_notes)\n",
    "#         plt.subplot(4, 4, i+1)\n",
    "#         image = generated_notes[i, :,]\n",
    "#         print(\"image shape\", images.shape)\n",
    "        \n",
    "    import random\n",
    "#     x_val = generated_notes\n",
    "#     ind = np.random.randint(0,len(x_val)-1)\n",
    "    \n",
    "#     random_music = x_val[ind]\n",
    "#     print(\"random_music shape\", random_music.shape)\n",
    "    predictions=[]\n",
    "#     no_of_timesteps = 100\n",
    "#     for i in range(10):\n",
    "\n",
    "#         random_music = random_music.reshape(1,no_of_timesteps)\n",
    "#         print(\"no_of_timesteps\", no_of_timesteps)\n",
    "    prob  = generated_notes\n",
    "#         print(\"prob_shape: \", prob.shape)\n",
    "    y_pred= np.argmax(prob,axis=0)\n",
    "#         print(\"y_pred: \", y_pred)\n",
    "    predictions.append(y_pred)\n",
    "    #         print(predictions)\n",
    "        \n",
    "    x_int_to_note = dict((number, note_) for number, note_ in enumerate(notes)) \n",
    "    predicted_notes = [x_int_to_note[i] for i in y_pred]\n",
    "    print(\"predicted_notes\", predicted_notes)\n",
    "    convert_to_midi(predicted_notes)\n",
    "    \n",
    "#     return message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_midi(prediction_output):\n",
    "    from music21 import stream\n",
    "#     from midi2audio import FluidSynth\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for pattern in prediction_output:\n",
    "        \n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                \n",
    "                cn=int(current_note)\n",
    "                new_note = note.Note(cn)\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "                \n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "            \n",
    "        # pattern is a note\n",
    "        else:\n",
    "             \n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()   # Piano\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 1\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp='music_206.mid')\n",
    "    message = \"Your music is ready to play\"\n",
    "#     return message\n",
    "#     play_file()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "\n",
    "from pygame import mixer\n",
    "\n",
    "def play_file():\n",
    "    root = Tk()\n",
    "\n",
    "    mixer.init()  # initializing the mixer\n",
    "\n",
    "    root.geometry('600x600')\n",
    "    root.title(\"Melody\")\n",
    "    root.iconbitmap(r'melody.ico')\n",
    "\n",
    "    text = Label(root, text='Press the button below to generate music')\n",
    "    text.pack()\n",
    "    \n",
    "\n",
    "    def play_music():\n",
    "        mixer.music.load(\"music_206.mid\")\n",
    "        mixer.music.play()\n",
    "\n",
    "\n",
    "    def stop_music():\n",
    "        mixer.music.stop()\n",
    "\n",
    "    playBtn = Button(root, text=\"Generate music\", width=40, command=notes_generator(samples=16))\n",
    "    playBtn.pack()\n",
    "    \n",
    "    playPhoto = PhotoImage(file='play.png')\n",
    "    playBtn = Button(root, image=playPhoto, command=play_music)\n",
    "    playBtn.pack()\n",
    "\n",
    "    stopPhoto = PhotoImage(file='stop.png')\n",
    "    stopBtn = Button(root, image=stopPhoto, command=stop_music)\n",
    "    stopBtn.pack()\n",
    "\n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_notes ['F6', 'D6', 'B-5', 'D5', 'D6', 'D6', 'A5', 'B-5', 'F6', 'A4', 'F6', 'F6', 'G6', 'F6', 'F6', 'F4', 'D6', 'F6', 'F6', 'G5', 'D5', 'A5', 'D5', 'B-5', 'B-5', 'B-5', 'F6', 'F6', 'D6', 'F6', 'F6', 'F6', 'F#5', 'B-5', 'F6', 'D5', 'F6', 'B-5', 'D6', 'B-5', 'D6', 'F#5', 'A4', 'F6', 'F6', 'B-5', 'D6', 'G4', 'B-5', 'B-5', 'F6', 'F6', 'F6', 'D5', 'D5', 'B-5', 'B-5', 'F6', 'F6', 'F6', 'F6', 'B-5', 'B-5', 'F6', 'D6', 'D5', 'F6', 'F6', 'D5', 'B-5', 'D6', 'F6', 'B-5', 'F6', 'D5', 'D6', 'D5', 'D6', 'B-5', 'F4', 'D6', 'F6', 'B-5', 'F6', 'B-5', 'D6', 'F6', 'D6', 'F4', 'A4', 'D5', 'B-5', 'B-5', 'B-5', 'D6', 'B-5', 'D6', 'F6', 'F4', 'D6']\n"
     ]
    }
   ],
   "source": [
    "play_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_notes ['A4', 'A4', 'D5', 'F#5', 'A4', 'B-5', 'A5', 'A4', 'G6', 'A5', 'A4', 'D5', 'A4', 'A4', 'A4', 'A5', 'A4', 'D5', 'A4', 'D5', 'G6', 'G5', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'D5', 'F4', 'A4', 'A4', 'G6', 'A4', 'A4', 'G5', 'A4', 'A4', 'B-5', 'A5', 'F#5', 'A4', 'G4', 'G6', 'F#5', 'G5', 'A4', 'A4', 'A4', 'A5', 'F#5', 'A4', 'A4', 'A4', 'F#5', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'G4', 'G4', 'A4', 'F#5', 'A4', 'A4', 'A4', 'G4', 'F#5', 'A4', 'F#5', 'A4', 'G4', 'D5', 'A4', 'G4', 'A4', 'A4', 'D5', 'A4', 'A4', 'G4', 'A5', 'D5', 'G4', 'A4', 'A4', 'A4', 'B-5', 'G4', 'G4', 'F#5', 'A4', 'A4']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6(tensorflow)'",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
